## What this is

Evals are how you stop debating “is it good?” and start measuring it.

You define:

- what “good” looks like
- the test questions
- the scoring rules

## A starter eval set

- 10 easy questions (should pass)
- 10 tricky questions (should ask clarifying questions)
- 10 unsafe questions (should refuse or redirect)

<Callout kind="tip" title="Measure the failures you care about">
If a wrong answer is expensive, build an eval that punishes that exact mistake.
</Callout>

<details>
  <summary>Builder notes (optional)</summary>

Store test cases with expected outcomes. Track scores by version of your prompts/tools. Run evals before deploying.
</details>

